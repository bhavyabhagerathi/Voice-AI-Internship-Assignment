# -*- coding: utf-8 -*-
"""Audio_Transcription.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RnvMznG_K5np0g0V0lDXTrqOM40-hml4

# SINGLE FUNCTION CODE AS PER YOUR REQUIREMENT

For more details about the code, please look into the ipynb file inside the zip file and refer to documentation.
"""

# Install necessary packages
!pip3 install transformers
!pip3 install datasets
!pip3 install accelerate

# Import required modules
import os
import torch
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline
from datasets import load_dataset

# Define the get_transcription function
def get_transcription(filename: str):
    """
    Get transcription for an audio file using ASR model.

    Parameters:
    - filename (str): Path to the audio file.

    Returns:
    - str: Transcription result.
    """
    # Initialize ASR model and tokenizer
    device_used = "cuda:0" if torch.cuda.is_available() else "cpu"
    dtype_used = torch.float16 if torch.cuda.is_available() else torch.float32

    asr_model_identifier = "openai/whisper-large-v3"
    asr_model = AutoModelForSpeechSeq2Seq.from_pretrained(
        asr_model_identifier, torch_dtype=dtype_used, use_safetensors=True
    )
    asr_model.to(device_used)

    asr_processor = AutoProcessor.from_pretrained(asr_model_identifier)

    # Set up ASR pipeline
    asr_pipeline = pipeline(
        "automatic-speech-recognition",
        model=asr_model,
        tokenizer=asr_processor.tokenizer,
        feature_extractor=asr_processor.feature_extractor,
        max_new_tokens=128,
        chunk_length_s=30,
        batch_size=16,
        return_timestamps=True,
        torch_dtype=dtype_used,
        device=device_used,
    )

    # Perform ASR on the provided audio file
    result = asr_pipeline(filename)

    # Return the transcription result
    return result["text"]

# Perform ASR on the provided audio file
audio_file_path = '/content/sample_data/common_voice_test/your_audio_file.wav'  # Replace with the actual file path
asr_result_file = get_transcription(audio_file_path)
print(f"Transcription for {audio_file_path}: {asr_result_file}")